{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hacker News Posts Project\n",
    "## Introduction\n",
    "Hacker News is a website where users submit their posts mainly concerning computer science and entrepreneurship, that can be voted and commented by other users, like Reddit.\n",
    "\n",
    "Since this project aims to practice with relatively simple data sets I will use a reduced version of the [Hacker News Posts data set](https://www.kaggle.com/hacker-news/hacker-news-posts), that instead of 300,000 rows uses only 20,000 rows obtained by removing the submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "The goal of the project is to compare two types of posts:\n",
    "- **Ask HN** : users submit Ask HN to ask the Hacker News community a specific question\n",
    "- **Show HN** : users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting\n",
    "\n",
    "I'll compare these two types of posts to determine:\n",
    "- Which type of post between Ask HN and Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "## Data preparation\n",
    "I start by importing the dataset in a list of list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv', encoding='utf8')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[:5]) # Display the first 5 rows, including the headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I separate the column headers from the list containing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm ready to filter out data. Since I want to concentrate my analysis only on posts with titles beginning with *Ask HN* or *Show HN*, I'll create a new list of list containing just the data with those characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    row_title = row[1]\n",
    "    if (row_title.lower().startswith('ask hn')):\n",
    "        ask_posts.append(row)\n",
    "    elif (row_title.lower().startswith('show hn')):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the post type with more comments on average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to compute the average number of comments for the two types of posts that I'm analyzing to find the one with the greatest number of comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for post in ask_posts:\n",
    "    total_ask_comments += int(post[4])\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results shown above, the post *Ask HN* posts receive on average 14 comments, 4 more than the *Show HN* posts. \n",
    "## Determine if posts created at a certain time receive more comments on average\n",
    "Since the *Ask HN* posts are the one more likely to receive comments, I'll focus my remaining analysis just on these posts. The steps that I will take are the following:\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received\n",
    "2. Calculate the average mumber of comments ask posts receive by hour created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for post in ask_posts:\n",
    "    result_list.append([post[6], int(post[4])]) # Append a new list containing the 'created_at' and the 'num_comments' columns\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comments = row[1]\n",
    "    datetime_object = dt.datetime.strptime(date, date_format)\n",
    "    hour = datetime_object.strftime(\"%H\") # Return the hour as a string\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "        \n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll use the two dictionaries I just created, *counts_by_hour* and *comments_by_hour*, to calculate the average number of comments for posts created during each hour of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['05', 10.08695652173913],\n",
       " ['08', 10.25],\n",
       " ['23', 7.985294117647059],\n",
       " ['18', 13.20183486238532],\n",
       " ['02', 23.810344827586206],\n",
       " ['07', 7.852941176470588],\n",
       " ['16', 16.796296296296298],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['15', 38.5948275862069],\n",
       " ['14', 13.233644859813085],\n",
       " ['01', 11.383333333333333],\n",
       " ['17', 11.46],\n",
       " ['11', 11.051724137931034],\n",
       " ['06', 9.022727272727273],\n",
       " ['13', 14.741176470588234],\n",
       " ['12', 9.41095890410959],\n",
       " ['10', 13.440677966101696],\n",
       " ['03', 7.796296296296297],\n",
       " ['22', 6.746478873239437],\n",
       " ['21', 16.009174311926607],\n",
       " ['19', 10.8],\n",
       " ['20', 21.525],\n",
       " ['09', 5.5777777777777775]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put this in a more readable way, by sorting the list of lists and by printing the five highest values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10.08695652173913, '05'],\n",
       " [10.25, '08'],\n",
       " [7.985294117647059, '23'],\n",
       " [13.20183486238532, '18'],\n",
       " [23.810344827586206, '02'],\n",
       " [7.852941176470588, '07'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [38.5948275862069, '15'],\n",
       " [13.233644859813085, '14'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.46, '17'],\n",
       " [11.051724137931034, '11'],\n",
       " [9.022727272727273, '06'],\n",
       " [14.741176470588234, '13'],\n",
       " [9.41095890410959, '12'],\n",
       " [13.440677966101696, '10'],\n",
       " [7.796296296296297, '03'],\n",
       " [6.746478873239437, '22'],\n",
       " [16.009174311926607, '21'],\n",
       " [10.8, '19'],\n",
       " [21.525, '20'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "for avg_hour in sorted_swap[:5]:\n",
    "    avg = avg_hour[0]\n",
    "    formatted_time = dt.datetime.strptime(avg_hour[1], '%H').strftime('%H:%M')\n",
    "    print(\n",
    "        '{}: {:.2f} average comments per post'.format(\n",
    "        formatted_time, \n",
    "        avg_hour[0]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "From the analysis performed above, I can conclude that the Ask Post category has a greater number of comments with respect with the Show Post category.\n",
    "\n",
    "Moreover, by analyzing the Ask Posts only, I found that posts created between 15:00 (=3 pm) and 16:00 (=4 pm) are the most commented, with an average of 38.59.\n",
    "Note that the timezone used in the data set is Eastern Time in the US, so if you live in Europe like me you can find useful this [time converter](https://www.thetimezoneconverter.com/) to find your local time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future improvements to this notebook\n",
    "In the future, I will enrich the analysis provided in this notebook by analyzing other aspects of the data set. Some ideas could be the followings:\n",
    "* Determine which kind of posts receive more points\n",
    "* Determine if posts created at a certain time are more likely to receive more points\n",
    "* Compare the results obtained with the comments with the ones obtained with the points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
